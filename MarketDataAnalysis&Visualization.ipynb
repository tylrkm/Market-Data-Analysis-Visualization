{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPY Market Data Analysis & Regime Dashboard (Portfolio Project)\n",
    "**by Tyler Moua**\n",
    "\n",
    "This notebook is an **analysis in Market Data** (not a trading strategy).\n",
    "It analyzes SPY using daily OHLCV data to understand:\n",
    "\n",
    "- Returns and drawdowns (market behavior)\n",
    "- Volatility clustering and regimes (risk behavior)\n",
    "- Tail risk (VaR/CVaR) and how it changes over time\n",
    "- Simple trend regimes (MA50/MA200) and what happens around regime switches\n",
    "- Whether volatility models (Rolling vs EWMA) describe **future realized volatility** better\n",
    "\n",
    "**Output:** A set of charts + quantitative tables + an executive summary suitable for GitHub/LinkedIn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "We import the required libraries, set plotting defaults, and define a CONFIG object.\n",
    "CONFIG makes the notebook reproducible and easy to adjust (lookback, MA windows, VaR window, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from QuantConnect.Research import QuantBook\n",
    "from QuantConnect import Resolution\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew, kurtosis, jarque_bera, ttest_ind\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 5)\n",
    "\n",
    "CONFIG = {\n",
    "    \"ticker\": \"SPY\",\n",
    "    \"lookback_days\": 252 * 15,\n",
    "    \"ma_short\": 50,\n",
    "    \"ma_long\": 200,\n",
    "    \"vol_windows\": [20, 60, 252],\n",
    "    \"ret_windows\": [21, 63, 252],\n",
    "    \"rolling_var_window\": 252,\n",
    "    \"high_vol_q\": 0.80,\n",
    "    \"event_window\": 10,\n",
    "    \"bootstrap_iters\": 5000,\n",
    "    \"seed\": 7,\n",
    "    \"ewma_lambda\": 0.94,\n",
    "    \"fig_dir\": \"figures\"\n",
    "}\n",
    "\n",
    "qb = QuantBook()\n",
    "os.makedirs(CONFIG[\"fig_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data ingestion (SPY)\n",
    "\n",
    "We pull daily historical OHLCV data for SPY using QuantConnect.\n",
    "We also ensure the output is a clean, numeric DataFrame indexed by date.\n",
    "This prevents plotting errors caused by symbol objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = CONFIG[\"ticker\"]\n",
    "spy = qb.AddEquity(ticker, Resolution.Daily).Symbol\n",
    "\n",
    "hist = qb.History(spy, CONFIG[\"lookback_days\"], Resolution.Daily)\n",
    "\n",
    "df = hist.loc[spy].copy()\n",
    "df = df.sort_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Integrity Checks\n",
    "\n",
    "We verify:\n",
    "- date range and number of rows\n",
    "- missing values\n",
    "- column types (should be numerifc for OHLCV)\n",
    "\n",
    "This is important for researc credibility and debuging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Date range:\", df.index.min(), \"→\", df.index.max())\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"\\nMissing values:\\n\", df.isna().sum())\n",
    "print(\"\\nDtypes:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feature engineering\n",
    "\n",
    "We compute the core market metrics:\n",
    "- returns (simple + log)\n",
    "- rolling returns (1M/3M/1Y approx)\n",
    "- rolling volatility (20D/60D/1Y)\n",
    "- moving averages (MA50/MA200)\n",
    "- drawdowns (risk)\n",
    "- volatility regime label (HighVol vs NormalVol)\n",
    "\n",
    "This turns raw OHLCV into a research dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(df, cfg):\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"ret_1d\"] = out[\"close\"].pct_change()\n",
    "    out[\"log_ret_1d\"] = np.log(out[\"close\"]).diff()\n",
    "\n",
    "    for w in cfg[\"ret_windows\"]:\n",
    "        out[f\"ret_{w}d\"] = (1 + out[\"ret_1d\"]).rolling(w).apply(np.prod, raw=True) - 1\n",
    "\n",
    "    for w in cfg[\"vol_windows\"]:\n",
    "        out[f\"vol_{w}d_ann\"] = out[\"ret_1d\"].rolling(w).std() * np.sqrt(252)\n",
    "\n",
    "    s, l = cfg[\"ma_short\"], cfg[\"ma_long\"]\n",
    "    out[f\"ma_{s}\"] = out[\"close\"].rolling(s).mean()\n",
    "    out[f\"ma_{l}\"] = out[\"close\"].rolling(l).mean()\n",
    "    out[\"trend_regime\"] = np.where(out[f\"ma_{s}\"] > out[f\"ma_{l}\"], \"Bull\", \"Bear\")\n",
    "\n",
    "    out[\"cum\"] = (1 + out[\"ret_1d\"]).cumprod()\n",
    "    out[\"peak\"] = out[\"cum\"].cummax()\n",
    "    out[\"drawdown\"] = out[\"cum\"] / out[\"peak\"] - 1\n",
    "\n",
    "    out[\"range_pct\"] = (out[\"high\"] - out[\"low\"]) / out[\"close\"]\n",
    "    out[\"gap_ret\"] = out[\"open\"] / out[\"close\"].shift(1) - 1\n",
    "\n",
    "    vol20 = out[\"vol_20d_ann\"]\n",
    "    thr = vol20.quantile(cfg[\"high_vol_q\"])\n",
    "    out[\"vol_regime\"] = np.where(vol20 >= thr, \"HighVol\", \"NormalVol\")\n",
    "\n",
    "    return out\n",
    "\n",
    "df = build_features(df, CONFIG)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Core dashboard visualization\n",
    "\n",
    "We create a multi-panel dashboard:\n",
    "- price + moving averages\n",
    "- rolling returns\n",
    "- rolling volatility\n",
    "- drawdown\n",
    "- trend regime indicator\n",
    "\n",
    "We save it to /figures for easy README embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, l = CONFIG[\"ma_short\"], CONFIG[\"ma_long\"]\n",
    "ret_cols = [f\"ret_{w}d\" for w in CONFIG[\"ret_windows\"]]\n",
    "vol_cols = [f\"vol_{w}d_ann\" for w in CONFIG[\"vol_windows\"]]\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(14, 18), sharex=True)\n",
    "\n",
    "axs[0].plot(df[\"close\"], label=\"Close\", alpha=0.85)\n",
    "axs[0].plot(df[f\"ma_{s}\"], label=f\"MA {s}\")\n",
    "axs[0].plot(df[f\"ma_{l}\"], label=f\"MA {l}\")\n",
    "axs[0].set_title(f\"{ticker} Price + Trend\")\n",
    "axs[0].legend()\n",
    "\n",
    "df[ret_cols].plot(ax=axs[1])\n",
    "axs[1].set_title(\"Rolling Returns (~1M / ~3M / ~1Y)\")\n",
    "axs[1].axhline(0, color=\"black\", lw=1)\n",
    "\n",
    "df[vol_cols].plot(ax=axs[2])\n",
    "axs[2].set_title(\"Rolling Annualized Volatility\")\n",
    "\n",
    "axs[3].plot(df[\"drawdown\"], color=\"tab:red\")\n",
    "axs[3].axhline(0, color=\"black\", lw=1)\n",
    "axs[3].set_title(\"Drawdown\")\n",
    "\n",
    "axs[4].plot((df[\"trend_regime\"] == \"Bull\").astype(int), color=\"tab:green\")\n",
    "axs[4].set_title(\"Trend Regime (Bull=1, Bear=0)\")\n",
    "axs[4].set_yticks([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"{CONFIG['fig_dir']}/dashboard.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Saved:\", f\"{CONFIG['fig_dir']}/dashboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Performance and risk summary\n",
    "\n",
    "We compute headline metrics to summarize the sample:\n",
    "- CAGR (annualized compounded growth)\n",
    "- annualized volatility\n",
    "- Sharpe ratio (rf=0)\n",
    "- maximum drawdown\n",
    "- Calmar ratio\n",
    "\n",
    "These numbers go into the final executive summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_report(df):\n",
    "    r = df[\"ret_1d\"].dropna()\n",
    "    n = len(r)\n",
    "\n",
    "    cagr = df[\"cum\"].iloc[-1] ** (252 / n) - 1\n",
    "    ann_vol = r.std() * np.sqrt(252)\n",
    "    sharpe = (r.mean() / r.std()) * np.sqrt(252)\n",
    "\n",
    "    max_dd = df[\"drawdown\"].min()\n",
    "    calmar = cagr / abs(max_dd)\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Start\": df.index.min(),\n",
    "        \"End\": df.index.max(),\n",
    "        \"Obs (days)\": n,\n",
    "        \"CAGR\": cagr,\n",
    "        \"Ann Vol\": ann_vol,\n",
    "        \"Sharpe (rf=0)\": sharpe,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Calmar\": calmar\n",
    "    })\n",
    "\n",
    "report = performance_report(df)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Return distribution and normality\n",
    "\n",
    "We quantify:\n",
    "- skewness and excess kurtosis (fat tails)\n",
    "- Jarque–Bera test (reject/accept normality)\n",
    "\n",
    "This supports the key idea that equity returns are not Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df[\"ret_1d\"].dropna()\n",
    "\n",
    "jb_stat, jb_p = jarque_bera(r.values)\n",
    "dist = pd.Series({\n",
    "    \"Mean (daily)\": r.mean(),\n",
    "    \"Std (daily)\": r.std(),\n",
    "    \"Skew\": skew(r.values),\n",
    "    \"Excess Kurtosis\": kurtosis(r.values),\n",
    "    \"Jarque–Bera p-value\": jb_p\n",
    "})\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(r, bins=60, density=True, alpha=0.75)\n",
    "plt.title(f\"{ticker} Daily Return Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(f\"{CONFIG['fig_dir']}/return_distribution.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Saved:\", f\"{CONFIG['fig_dir']}/return_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Tail risk (VaR / CVaR)\n",
    "\n",
    "We compute:\n",
    "- VaR (quantile loss threshold)\n",
    "- CVaR (average loss beyond VaR)\n",
    "\n",
    "We also compute rolling 1Y VaR/CVaR to visualize how tail risk changes through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_cvar(x: pd.Series, alpha: float):\n",
    "    x = x.dropna()\n",
    "    var = np.quantile(x, alpha)\n",
    "    cvar = x[x <= var].mean()\n",
    "    return float(var), float(cvar)\n",
    "\n",
    "var95, cvar95 = var_cvar(r, 0.05)\n",
    "var99, cvar99 = var_cvar(r, 0.01)\n",
    "\n",
    "tail = pd.Series({\n",
    "    \"VaR 95% (daily)\": var95,\n",
    "    \"CVaR 95% (daily)\": cvar95,\n",
    "    \"VaR 99% (daily)\": var99,\n",
    "    \"CVaR 99% (daily)\": cvar99\n",
    "})\n",
    "tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = CONFIG[\"rolling_var_window\"]\n",
    "\n",
    "df[\"VaR95_1y\"] = df[\"ret_1d\"].rolling(W).quantile(0.05)\n",
    "\n",
    "def rolling_cvar(series, window, alpha):\n",
    "    vals = series.values\n",
    "    out = np.full(len(series), np.nan)\n",
    "    for i in range(window-1, len(series)):\n",
    "        w = vals[i-window+1:i+1]\n",
    "        w = w[~np.isnan(w)]\n",
    "        if len(w) == 0:\n",
    "            continue\n",
    "        v = np.quantile(w, alpha)\n",
    "        tail = w[w <= v]\n",
    "        out[i] = tail.mean() if len(tail) else np.nan\n",
    "    return pd.Series(out, index=series.index)\n",
    "\n",
    "df[\"CVaR95_1y\"] = rolling_cvar(df[\"ret_1d\"], W, 0.05)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "df[\"VaR95_1y\"].plot(label=\"Rolling VaR 95% (1Y)\", color=\"tab:orange\")\n",
    "df[\"CVaR95_1y\"].plot(label=\"Rolling CVaR 95% (1Y)\", color=\"tab:red\", alpha=0.85)\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.title(\"Rolling Tail Risk (1Y window)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(f\"{CONFIG['fig_dir']}/rolling_var_cvar.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Saved:\", f\"{CONFIG['fig_dir']}/rolling_var_cvar.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Regimes and regime transitions\n",
    "\n",
    "We summarize return and risk statistics by:\n",
    "- trend regime (Bull/Bear via MA50/MA200)\n",
    "- volatility regime (HighVol vs NormalVol)\n",
    "\n",
    "Then we run an event study around **regime switches** to see how returns and volatility behave near transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = df.dropna(subset=[\"ret_1d\", \"trend_regime\", \"vol_regime\", \"drawdown\"])\n",
    "\n",
    "def ann_stats(sub):\n",
    "    rr = sub[\"ret_1d\"].dropna()\n",
    "    return pd.Series({\n",
    "        \"Count\": len(rr),\n",
    "        \"Time Share\": len(rr) / len(reg),\n",
    "        \"Ann Return\": rr.mean() * 252,\n",
    "        \"Ann Vol\": rr.std() * np.sqrt(252),\n",
    "        \"Sharpe (rf=0)\": (rr.mean() / rr.std()) * np.sqrt(252),\n",
    "        \"Max DD\": sub[\"drawdown\"].min()\n",
    "    })\n",
    "\n",
    "trend_stats = reg.groupby(\"trend_regime\").apply(ann_stats)\n",
    "vol_stats = reg.groupby(\"vol_regime\").apply(ann_stats)\n",
    "\n",
    "trend_stats, vol_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_k = CONFIG[\"event_window\"]\n",
    "\n",
    "reg2 = df.dropna(subset=[\"trend_regime\", \"ret_1d\", \"vol_20d_ann\"]).copy()\n",
    "switch = reg2[\"trend_regime\"].ne(reg2[\"trend_regime\"].shift(1))\n",
    "switch_dates = reg2.index[switch].tolist()\n",
    "\n",
    "def build_event_matrix(series, dates, k):\n",
    "    cols = list(range(-k, k+1))\n",
    "    mat = []\n",
    "    idx = series.index\n",
    "    for d in dates:\n",
    "        if d not in idx:\n",
    "            continue\n",
    "        pos = idx.get_loc(d)\n",
    "        if isinstance(pos, slice):\n",
    "            continue\n",
    "        if pos - k < 0 or pos + k >= len(idx):\n",
    "            continue\n",
    "        mat.append(series.iloc[pos-k:pos+k+1].values)\n",
    "    return pd.DataFrame(mat, columns=cols)\n",
    "\n",
    "event_ret = build_event_matrix(reg2[\"ret_1d\"], switch_dates, event_k)\n",
    "event_vol = build_event_matrix(reg2[\"vol_20d_ann\"], switch_dates, event_k)\n",
    "\n",
    "avg_ret = event_ret.mean(axis=0)\n",
    "avg_vol = event_vol.mean(axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "ax[0].plot(avg_ret.index, avg_ret.values, marker=\"o\")\n",
    "ax[0].axvline(0, color=\"black\", lw=1)\n",
    "ax[0].axhline(0, color=\"black\", lw=1)\n",
    "ax[0].set_title(\"Event Study: Average Daily Return Around Regime Switch (t=0 is switch)\")\n",
    "\n",
    "ax[1].plot(avg_vol.index, avg_vol.values, marker=\"o\", color=\"tab:purple\")\n",
    "ax[1].axvline(0, color=\"black\", lw=1)\n",
    "ax[1].set_title(\"Event Study: Average 20D Ann Vol Around Regime Switch\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"{CONFIG['fig_dir']}/regime_transition_event_study.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Saved:\", f\"{CONFIG['fig_dir']}/regime_transition_event_study.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Hypothesis testing (with bootstrap confidence intervals)\n",
    "\n",
    "We test two intuitive hypotheses:\n",
    "- H1: Volatility is higher during drawdowns than at all-time highs\n",
    "- H2: Mean returns differ between Bull vs Bear regimes\n",
    "\n",
    "We complement t-tests with bootstrap confidence intervals for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dd = df[df[\"drawdown\"] < 0][\"vol_20d_ann\"].dropna()\n",
    "out_dd = df[df[\"drawdown\"] == 0][\"vol_20d_ann\"].dropna()\n",
    "t1, p1 = ttest_ind(in_dd, out_dd, equal_var=False)\n",
    "\n",
    "bull = df[df[\"trend_regime\"] == \"Bull\"][\"ret_1d\"].dropna()\n",
    "bear = df[df[\"trend_regime\"] == \"Bear\"][\"ret_1d\"].dropna()\n",
    "t2, p2 = ttest_ind(bull, bear, equal_var=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Test\": [\"H1: Vol higher in drawdowns\", \"H2: Returns differ Bull vs Bear\"],\n",
    "    \"t-stat\": [t1, t2],\n",
    "    \"p-value\": [p1, p2],\n",
    "    \"Mean A\": [in_dd.mean(), bull.mean()],\n",
    "    \"Mean B\": [out_dd.mean(), bear.mean()]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_diff_means(a, b, iters=5000, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    a = np.asarray(a); b = np.asarray(b)\n",
    "    a = a[~np.isnan(a)]; b = b[~np.isnan(b)]\n",
    "    diffs = np.empty(iters)\n",
    "    for i in range(iters):\n",
    "        diffs[i] = rng.choice(a, size=len(a), replace=True).mean() - rng.choice(b, size=len(b), replace=True).mean()\n",
    "    return np.quantile(diffs, [0.025, 0.5, 0.975])\n",
    "\n",
    "ci_h1 = bootstrap_diff_means(in_dd.values, out_dd.values, CONFIG[\"bootstrap_iters\"], CONFIG[\"seed\"])\n",
    "ci_h2 = bootstrap_diff_means(bull.values, bear.values, CONFIG[\"bootstrap_iters\"], CONFIG[\"seed\"])\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Test\": [\"H1: mean(vol) inDD - outDD\", \"H2: mean(ret) Bull - Bear\"],\n",
    "    \"Diff Mean (A-B)\": [in_dd.mean() - out_dd.mean(), bull.mean() - bear.mean()],\n",
    "    \"CI 2.5%\": [ci_h1[0], ci_h2[0]],\n",
    "    \"CI 50%\": [ci_h1[1], ci_h2[1]],\n",
    "    \"CI 97.5%\": [ci_h1[2], ci_h2[2]],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Stress window case studies\n",
    "\n",
    "We quantify market behavior during:\n",
    "- COVID crash period\n",
    "- 2022 tightening / drawdown period\n",
    "\n",
    "This gives real-world context and illustrates how risk concentrates in short episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_stats(df, start, end):\n",
    "    w = df.loc[start:end].dropna(subset=[\"ret_1d\"])\n",
    "    rr = w[\"ret_1d\"]\n",
    "    return pd.Series({\n",
    "        \"Start\": w.index.min(),\n",
    "        \"End\": w.index.max(),\n",
    "        \"Total Return\": (1 + rr).prod() - 1,\n",
    "        \"Ann Vol\": rr.std() * np.sqrt(252),\n",
    "        \"Max DD\": w[\"drawdown\"].min(),\n",
    "        \"Worst Day\": rr.min(),\n",
    "        \"Best Day\": rr.max(),\n",
    "        \"Days\": len(rr)\n",
    "    })\n",
    "\n",
    "stress = pd.DataFrame({\n",
    "    \"COVID Crash\": window_stats(df, \"2020-02-15\", \"2020-04-30\"),\n",
    "    \"2022 Tightening\": window_stats(df, \"2022-01-01\", \"2022-10-31\"),\n",
    "}).T\n",
    "\n",
    "stress\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "df[\"close\"].plot()\n",
    "plt.axvspan(\"2020-02-15\", \"2020-04-30\", color=\"red\", alpha=0.15, label=\"COVID Crash\")\n",
    "plt.axvspan(\"2022-01-01\", \"2022-10-31\", color=\"orange\", alpha=0.15, label=\"2022 Tightening\")\n",
    "plt.title(\"SPY with Stress Windows Highlighted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(f\"{CONFIG['fig_dir']}/stress_windows.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Saved:\", f\"{CONFIG['fig_dir']}/stress_windows.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Volatility modeling and evaluation (research, not trading)\n",
    "\n",
    "We compute EWMA volatility (RiskMetrics-style) and compare it to rolling 20D volatility.\n",
    "Then we evaluate both as **forecast proxies** for future realized volatility:\n",
    "\n",
    "- Target: next 20-day realized volatility (annualized)\n",
    "- Metrics: RMSE/MAE/correlation against the target\n",
    "\n",
    "This answers: **does a smarter risk model better describe future risk?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = CONFIG.get(\"ewma_lambda\", 0.94)\n",
    "ret0 = df[\"ret_1d\"].fillna(0)\n",
    "\n",
    "ewma_var = np.zeros(len(ret0))\n",
    "for i in range(1, len(ret0)):\n",
    "    ewma_var[i] = lam * ewma_var[i-1] + (1 - lam) * (ret0.iloc[i-1] ** 2)\n",
    "\n",
    "df[\"ewma_vol_ann\"] = np.sqrt(ewma_var) * np.sqrt(252)\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "df[[\"vol_20d_ann\", \"ewma_vol_ann\"]].plot(title=f\"Rolling 20D Vol vs EWMA Vol (Annualized) | lambda={lam}\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(f\"{CONFIG['fig_dir']}/ewma_vol.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Saved:\", f\"{CONFIG['fig_dir']}/ewma_vol.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 20\n",
    "df[\"realized_vol_fwd_20d_ann\"] = df[\"ret_1d\"].rolling(h).std().shift(-h) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = df[[\"vol_20d_ann\", \"ewma_vol_ann\", \"realized_vol_fwd_20d_ann\"]].dropna().copy()\n",
    "y = eval_df[\"realized_vol_fwd_20d_ann\"]\n",
    "\n",
    "def metrics(pred, y):\n",
    "    err = pred - y\n",
    "    return pd.Series({\n",
    "        \"RMSE\": np.sqrt(np.mean(err**2)),\n",
    "        \"MAE\": np.mean(np.abs(err)),\n",
    "        \"Corr\": np.corrcoef(pred, y)[0, 1]\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Rolling20D\": metrics(eval_df[\"vol_20d_ann\"], y),\n",
    "    \"EWMA\": metrics(eval_df[\"ewma_vol_ann\"], y),\n",
    "}).T\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plot_df = eval_df.tail(252 * 3)\n",
    "\n",
    "plot_df[\"realized_vol_fwd_20d_ann\"].plot(label=\"Future Realized Vol (next 20D)\", color=\"black\", linewidth=2, alpha=0.8)\n",
    "plot_df[\"vol_20d_ann\"].plot(label=\"Rolling 20D Vol\", color=\"tab:blue\", alpha=0.85)\n",
    "plot_df[\"ewma_vol_ann\"].plot(label=f\"EWMA Vol (λ={lam})\", color=\"tab:green\", alpha=0.85)\n",
    "\n",
    "plt.title(\"Vol Forecast Evaluation: Rolling vs EWMA vs Future Realized Vol\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(f\"{CONFIG['fig_dir']}/vol_forecast_evaluation.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Saved:\", f\"{CONFIG['fig_dir']}/vol_forecast_evaluation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Executive summary (auto-generated)\n",
    "\n",
    "We generate a compact summary (numbers + conclusions) that can be pasted directly into:\n",
    "- GitHub README\n",
    "- LinkedIn post\n",
    "- college application portfolio description\n",
    "\n",
    "This is where the notebook becomes a shareable artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
